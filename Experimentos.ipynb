{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8ECla71sbOo"
   },
   "source": [
    "# **Projeto AM 2019.1 - K-medoid-fuzzy-cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyGbugxdsu_I"
   },
   "source": [
    "***Parte 1 - Implementação e Execução do Algoritmo MVFCMddV***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASLYN11VzjpI"
   },
   "source": [
    "Importação das bibliotecas usadas no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDOaD4AEsfhh"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, RepeatedStratifiedKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from numpy.linalg import inv, det\n",
    "from statistics import mean\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXJZssTO0BgG"
   },
   "source": [
    "Extração dos dados de csv para matrizes em Python e normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpsYLoJ6wdA4"
   },
   "outputs": [],
   "source": [
    "def ExtractData (filename):\n",
    "\n",
    "    features = []\n",
    "    classes = []\n",
    "    \n",
    "    file = open(filename, 'r')\n",
    "\n",
    "    for i in range(10):\n",
    "        classes.append([i]*200)\n",
    "\n",
    "    for line in file:\n",
    "        row = line.split(';')\n",
    "        features.append([float(x) for x in row ])\n",
    "\n",
    "    mat_feat = np.matrix(features).astype(np.float)\n",
    "\n",
    "    #matriz de dados\n",
    "    return (mat_feat)\n",
    "\n",
    "mat_fac = ExtractData('mfeat-fac.csv').astype(int)\n",
    "mat_fou = ExtractData('mfeat-fou.csv')\n",
    "mat_kar = ExtractData('mfeat-kar.csv')\n",
    "\n",
    "#normalização dos dados\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "fac = std.fit_transform(mat_fac)\n",
    "fou = std.fit_transform(mat_fou)\n",
    "kar = std.fit_transform(mat_kar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dwsvnymg0IOs"
   },
   "source": [
    "Cálculo das dissimilaridades usando a distância euclidiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqYKmN3Wwggd"
   },
   "outputs": [],
   "source": [
    "#calculo das matrizes de dissimilaridade\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "\n",
    "#dados não normalizados:\n",
    "#distancias_fac = pdist(mat_fac, metric='euclidean')\n",
    "#distancias_fou = pdist(mat_fou, metric='euclidean')\n",
    "#distancias_kar = pdist(mat_kar, metric='euclidean')\n",
    "\n",
    "#considerando os dados normalizados\n",
    "\n",
    "distancias_fac = pdist(fac, metric='euclidean')\n",
    "distancias_fou = pdist(fou, metric='euclidean')\n",
    "distancias_kar = pdist(kar, metric='euclidean')\n",
    "\n",
    "mfeat_fac = squareform(distancias_fac)\n",
    "mfeat_fou = squareform(distancias_fou)\n",
    "mfeat_kar = squareform(distancias_kar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWrul9xJ0WV4"
   },
   "source": [
    "Funções das etapas de inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oyQF0e2qwhfP"
   },
   "outputs": [],
   "source": [
    "def initialize_medoid_vector(G):\n",
    "  iterator = np.nditer(G, op_flags=['readwrite'],flags=['multi_index'])\n",
    "  while not iterator.finished:\n",
    "      G[iterator.multi_index] = rdm.randint(2000)\n",
    "      iterator.iternext()\n",
    "  return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sskNovKwkc1"
   },
   "outputs": [],
   "source": [
    "def initialize_relevanceWeights(K,p):\n",
    "  \n",
    "  return np.ones((K,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7wnczT41O65"
   },
   "source": [
    "Funções das etapas de atualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7vU2m-Twmhl"
   },
   "outputs": [],
   "source": [
    "def update_medoid_vector(G,D,U,n):\n",
    "  iterator = np.nditer(G,op_flags=['readwrite'],flags=['multi_index'])\n",
    "\n",
    "  while not iterator.finished:\n",
    "      k = iterator.multi_index[0]\n",
    "      dissimilarities_sum = np.zeros([n])\n",
    "      dissimilarity_matrix = D[iterator.multi_index[1]]\n",
    "      \n",
    "      for h in range(n):\n",
    "        medoid_sum = 0\n",
    "        medoid_sum += sum((U[:,k]**m)*(dissimilarity_matrix[:,h]))\n",
    "        dissimilarities_sum[h]=medoid_sum\n",
    "      G[iterator.multi_index]=(np.argmin(dissimilarities_sum))\n",
    "\n",
    "      iterator.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GyvFr0gwr1Z"
   },
   "outputs": [],
   "source": [
    "def update_fuzzy_partition(U,G,D,relevance_weights):\n",
    "  UI = []\n",
    "  iterator = np.nditer(U,op_flags=['readwrite'],flags=['multi_index'])\n",
    "\n",
    "  while not iterator.finished:\n",
    "      dissimilarity_to_k = 0\n",
    "      for j in range(p):\n",
    "        dissimilarity_matrix = D[j]\n",
    "        i = iterator.multi_index[0]\n",
    "        k = iterator.multi_index[1]\n",
    "\n",
    "        medoidIndex = int(G[k][j])\n",
    "\n",
    "        dissimilarity_to_k += (relevance_weights[k,j]*dissimilarity_matrix[i,medoidIndex])\n",
    "      u = 0\n",
    "      for h in range(K):\n",
    "        dissimilarities_to_h = 0  \n",
    "        for j in range(p):\n",
    "          dissimilarity_matrix = D[j]\n",
    "\n",
    "          medoidIndex = int(G[h][j])\n",
    "          dissimilarities_to_h += (relevance_weights[h,j] *dissimilarity_matrix[i,medoidIndex])\n",
    "\n",
    "\n",
    "        u += ( dissimilarity_to_k / float(dissimilarities_to_h))**( 1/(m-1)) \n",
    "\n",
    "      U[iterator.multi_index] = u**(-1)\n",
    "      UI=[]\n",
    "      iterator.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATIA-WbNws_c"
   },
   "outputs": [],
   "source": [
    "def update_relevance_weights(relevance_weights,G,U,D):\n",
    "  \n",
    "  iterator = np.nditer(relevance_weights, op_flags=['readwrite'],flags=['multi_index'])\n",
    "  \n",
    "  while not iterator.finished:\n",
    "      k = iterator.multi_index[0]\n",
    "      j = iterator.multi_index[1]\n",
    "      multiplicator = 1\n",
    "      for h in range(p):\n",
    "        weighted_distance_sum = 0\n",
    "        dissimilarity_matrix = D[h]\n",
    "        medoid_index = int(G[k][h])\n",
    "        weighted_distance_sum += sum((U[:,k]**m)*(dissimilarity_matrix[:,medoid_index]))\n",
    "\n",
    "        multiplicator *= weighted_distance_sum\n",
    "\n",
    "      distance_sum = 0\n",
    "      dissimilarity_matrix = D[j]\n",
    "      medoid_index = int(G[k][j])\n",
    "      distance_sum += sum((U[:,k]**m)*(dissimilarity_matrix[:,medoid_index]))\n",
    "      lambda_kj = ((multiplicator**(1/p))/distance_sum)\n",
    "      relevance_weights[k,j]=lambda_kj\n",
    "      iterator.iternext()\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jv324Pg1d1o"
   },
   "source": [
    "Calculo do valor da Função Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onMeIP6QwvmC"
   },
   "outputs": [],
   "source": [
    "def adequacy_criteion(G,U,D,m,relevance_weights,p):\n",
    "  J = 0\n",
    "  for k in range (K):\n",
    "    \n",
    "    for i in range(n):\n",
    "      \n",
    "      weighted_distance = 0\n",
    "      for j in range(p):\n",
    "        dissimilarity_matrix = D[j]\n",
    "        medoid_index = int(G[k][j])\n",
    "        weighted_distance += (relevance_weights[k,j])* dissimilarity_matrix[i,medoid_index] \n",
    "      J += (U[i,k]**m) * weighted_distance\n",
    "        \n",
    "  return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1pDMXl11ol0"
   },
   "source": [
    "Função para checar se foram gerados 10 grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J5GHTGtkAnyx"
   },
   "outputs": [],
   "source": [
    "def check_empty_cluster(U):\n",
    "  \n",
    "  count = np.argmax(U, axis=1)\n",
    "  \n",
    "  if(len(list(set(count))) == 10):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oTiazfGC18Et"
   },
   "source": [
    "Algoritmo de Agrupamento MVFCMddV \n",
    "\n",
    "Usa como entrada:\n",
    "*   D - lista com p matrizes de dissimilaridades com n exemplos\n",
    "*   m - taxa de aprendizagem\n",
    "*   k - número de clusters\n",
    "*   epsilon - critério de convergência\n",
    "*   T - número máximo de iterações\n",
    "\n",
    "Retorna como saída:\n",
    "*   U - matriz de pertencimento\n",
    "*   W - matriz de pesos de relevância\n",
    "*   G - matriz de medoids\n",
    "*   J_Iteractions - lista com os valores das funções objetivos das iterações\n",
    "*   J - valor da função objetivo final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_cR7c6s18Rz"
   },
   "outputs": [],
   "source": [
    "def fuzzy_clustering():\n",
    "  # Configuração inicial do algoritmo\n",
    "\n",
    "  D = [mfeat_fac, mfeat_fou, mfeat_kar]\n",
    "  n = mat_fac.shape[0]\n",
    "  m = 1.6 \n",
    "  K = 10\n",
    "  p = len(D)\n",
    "\n",
    "  # Configuração inicial do algoritmo\n",
    "\n",
    "  # U -> Matriz nxk Grau de pertencimento\n",
    "  # G -> Vetor de vetores metoids\n",
    "  # Lambda -> Vetor de vetores de relevância de peso\n",
    "\n",
    "  # Inicialização \n",
    "  # Nível de fuzzyficação\n",
    "  G = np.zeros((K,p))\n",
    "  U = np.zeros((n,K))\n",
    "  T = 150\n",
    "  epsilon = 10**-10\n",
    "\n",
    "  # Inicialização das matrizes G, relevance_weights (Lambda) e U75563\n",
    "  initialize_medoid_vector(G)\n",
    "  relevance_weights = initialize_relevanceWeights(K,p)\n",
    "  update_fuzzy_partition(U,G,D,relevance_weights)\n",
    "  J = adequacy_criteion(G,U,D,m,relevance_weights,p)\n",
    "  # Começar as iterações do algoritmo\n",
    "  t=0\n",
    "  \n",
    "  best_local_J = J\n",
    "  best__local_G = np.zeros((K,p))\n",
    "  best_local_U = np.zeros((n,K))\n",
    "  best_local_relevance_weights = initialize_relevanceWeights(1,3)\n",
    "  \n",
    "  J_values = [J]\n",
    "  \n",
    "  while(t < T):\n",
    "    #print(J)\n",
    "    t += 1\n",
    "    update_medoid_vector(G,D,U,n)\n",
    "    update_relevance_weights(relevance_weights,G,U,D)\n",
    "    update_fuzzy_partition(U,G,D,relevance_weights)\n",
    "    old_J = J\n",
    "    J = adequacy_criteion(G,U,D,m,relevance_weights,p)\n",
    "    \n",
    "    J_values.append(J)\n",
    "    \n",
    "    if(J < best_local_J):\n",
    "      best_local_G = G\n",
    "      best_local_U = U\n",
    "      best_local_relevance_weights = relevance_weights\n",
    "      best_local_J = J  \n",
    "    #print(best_local_J)\n",
    "    if(abs(old_J - J) < epsilon):\n",
    "      break\n",
    "  return({\"J\": best_local_J, \"G\": best_local_G, \"U\": best_local_U, \"W\": best_local_relevance_weights, \"J_Iteractions\": J_values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsGLl1vi14aO"
   },
   "source": [
    "Função para calcular o Rand Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5U8DcSqO3uU"
   },
   "outputs": [],
   "source": [
    "def calculate_rand_score(U):\n",
    "  Y_crisp = np.argmax(U, axis=1)\n",
    "  true_labels =  np.arange(10*200) // 200\n",
    "  return adjusted_rand_score(true_labels,Y_crisp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MW8_Yx1F4TMY"
   },
   "source": [
    "Célula com algoritmo para executar o algoritmo de agrupamento 100 vezes e armazenar a saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OVcY6k4w-n16",
    "outputId": "05b2441e-887b-435c-e09b-09cc4d324556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8462a1a5612e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzzy_clustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7c5b75692cfa>\u001b[0m in \u001b[0;36mfuzzy_clustering\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#print(J)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mupdate_medoid_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mupdate_relevance_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevance_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mupdate_fuzzy_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrelevance_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-79afac80e946>\u001b[0m in \u001b[0;36mupdate_medoid_vector\u001b[0;34m(G, D, U, n)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmedoid_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmedoid_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdissimilarity_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdissimilarities_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmedoid_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdissimilarities_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D = [mfeat_fac, mfeat_fou, mfeat_kar]\n",
    "p = len(D)\n",
    "n = mat_fac.shape[0]\n",
    "m = 1.6 \n",
    "K = 10\n",
    "rdm = np.random.RandomState(2)\n",
    "\n",
    "best_J_list = []\n",
    "rand_score_list = []\n",
    "J_Interactions_list = []\n",
    "times_list = []\n",
    "u_list = []\n",
    "\n",
    "best_J = math.inf\n",
    "it = 0\n",
    "while(it<100):\n",
    "  print(it)\n",
    "  \n",
    "  start = time.time()\n",
    "  out = fuzzy_clustering()\n",
    "  end = time.time()\n",
    "  \n",
    "  best_J_list.append(out[\"J\"])\n",
    "  J_Interactions_list.append(out[\"J_Iteractions\"])\n",
    "  rand_score_list.append(calculate_rand_score(out[\"U\"]))\n",
    "  times_list.append(end - start)\n",
    "  u_list.append(out[\"U\"])\n",
    "  \n",
    "  #print(\"Melhor J:\",out[\"J\"])\n",
    "  if(out[\"J\"] < best_J) and (check_empty_cluster(out[\"U\"])):\n",
    "    best_G = out[\"G\"]\n",
    "    best_U = out[\"U\"]\n",
    "    best_relevance_weights = out[\"W\"]\n",
    "    best_J = out[\"J\"]\n",
    "  \n",
    "  it = it+1  \n",
    "\n",
    "Y_crisp = np.argmax(best_U, axis=1)\n",
    "\n",
    "print(best_J)\n",
    "print(set(Y_crisp))\n",
    "print(best_J_list)\n",
    "print(rand_score_list)\n",
    "print(J_Interactions_list)\n",
    "print(times_list)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experimentos.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
